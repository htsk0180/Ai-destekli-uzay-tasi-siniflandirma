{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaya sınıfı yapan Aİ modeli\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Harika! AI programınız için ihtiyacınız olacak tüm kitaplıkları kod olarak eklediniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verileri temizlemek ve ayırmak için kodumuzu yazalım.\n",
    "#Görüntüleri görselleştirmek için Python görüntüleme kitaplığını (PIL) kullanacağız..\n",
    "# veri yolunu belirtelim.\n",
    "data_dir = './Data'\n",
    "\n",
    "\n",
    "def load_split_train_test(data_dir, valid_size = .2):\n",
    "\n",
    "    # Modeli eğitmek için görüntüleri dönüştürelim.\n",
    "    train_transforms = transforms.Compose([\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.Resize(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       ])\n",
    "\n",
    "    # Modeli test etmek için görüntüleri dönüştürelim.\n",
    "    test_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                          transforms.Resize(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                      ])\n",
    "\n",
    "    # Eğitim ve test görüntüleri ile klasörler için iki değişken oluşturalım.\n",
    "    train_data = datasets.ImageFolder(data_dir, transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
    "\n",
    "    # Eğitim klasöründeki resim sayısını alın\n",
    "    num_train = len(train_data)\n",
    "\n",
    "    # 0'dan eğitim resimlerinin sayısına kadar sayıların bir listesini oluşturun - 1\n",
    "    # Örnek: 10 resim için değişken listedir [0,1,2,3,4,5,6,7,8,9]\n",
    "    indices = list(range(num_train))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    \n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "   \n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
    "\n",
    "   \n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainloader, testloader = load_split_train_test(data_dir, .2)\n",
    "\n",
    "\n",
    "print(trainloader.dataset.classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bir görüntüyü piksele dönüştürrüyoruz ve yeniden boyutlandırıyoruz.\n",
    "test_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                   transforms.Resize(224),\n",
    "                                   transforms.ToTensor(),\n",
    "                                 ])\n",
    "\n",
    "# Rastgele bir görüntü kümesi seçiyoruz.\n",
    "def get_random_images(num):\n",
    "    data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
    "    classes = data.classes\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n",
    "\n",
    "   \n",
    "    dataiter = iter(loader)\n",
    "\n",
    "    \n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images, labels = get_random_images(5)\n",
    "\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "fig=plt.figure(figsize=(20,20))\n",
    "\n",
    "\n",
    "classes=trainloader.dataset.classes\n",
    "\n",
    "\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for param in model.parameters():\n",
    "     param.requires_grad = False\n",
    "\n",
    "\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Dropout(0.2),\n",
    "                               nn.Linear(512, 2),\n",
    "                               nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 5\n",
    "print_every = 5\n",
    "\n",
    "\n",
    "running_loss = 0\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "\n",
    "steps = 0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "   \n",
    "   epoch += 1\n",
    "\n",
    "    \n",
    "   for inputs, labels in trainloader:\n",
    "\n",
    "      \n",
    "      steps += 1\n",
    "      print('Training step ', steps)\n",
    "\n",
    "      \n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      \n",
    "      logps = model.forward(inputs)\n",
    "\n",
    "      \n",
    "      loss = criterion(logps, labels)\n",
    "\n",
    "      \n",
    "      loss.backward()\n",
    "\n",
    "      \n",
    "      optimizer.step()\n",
    "\n",
    "      \n",
    "      running_loss += loss.item()\n",
    "\n",
    "      \n",
    "      if steps % print_every == 0:\n",
    "\n",
    "         \n",
    "         test_loss = 0\n",
    "         accuracy = 0\n",
    "\n",
    "         \n",
    "         model.eval()\n",
    "\n",
    "         \n",
    "         with torch.no_grad():\n",
    "\n",
    "             \n",
    "            for inputs, labels in testloader:\n",
    "\n",
    "               \n",
    "               inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "               \n",
    "               logps = model.forward(inputs)\n",
    "\n",
    "               \n",
    "               batch_loss = criterion(logps, labels)\n",
    "\n",
    "               \n",
    "               test_loss += batch_loss.item()\n",
    "\n",
    "               \n",
    "               ps = torch.exp(logps)\n",
    "\n",
    "               \n",
    "               top_p, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "               \n",
    "               equals = top_class == labels.view(*top_class.shape)\n",
    "\n",
    "               \n",
    "               accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "         \n",
    "         train_losses.append(running_loss/len(trainloader))\n",
    "         test_losses.append(test_loss/len(testloader))  \n",
    "\n",
    "        \n",
    "         print(f\"\\n     Epoch {epoch}/{epochs}: \"\n",
    "               f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "               f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "               f\"Test accuracy: {accuracy/len(testloader):.3f}\\n\")\n",
    "\n",
    "         \n",
    "         running_loss = 0\n",
    "         model.train()\n",
    "\n",
    "        \n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy/len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'aerialmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=torch.load('aerialmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    image_tensor = test_transforms(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "images, labels = get_random_images(5)\n",
    "fig=plt.figure(figsize=(20,10))\n",
    "\n",
    "\n",
    "classes=trainloader.dataset.classes\n",
    "\n",
    "\n",
    "for ii in range(len(images)):\n",
    "\n",
    "   \n",
    "    image = to_pil(images[ii])\n",
    "    index = predict_image(image)\n",
    "\n",
    "    \n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    res = int(labels[ii]) == index\n",
    "    sub.set_title(str(classes[index]) + \":\" + str(res))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "images, labels = get_random_images(20)\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03d8e469bfbc516284214c0196f4ed5f3b7542b40c007b142042eca12ba956c9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
